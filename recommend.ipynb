{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "17PhBd_M5cxuSRzAa1qldVbUDLvOyfP1n",
      "authorship_tag": "ABX9TyMazGmOM7fOCVQBGojZoHd5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeommoKoo-dev/recommender-system/blob/beommo/recommend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmndZ7QIuH6K"
      },
      "outputs": [],
      "source": [
        "!pip install keybert\n",
        "!pip install POT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keybert import KeyBERT\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "import seaborn as sns\n",
        "\n",
        "from gensim.models import LdaModel\n",
        "from gensim import corpora\n",
        "from sklearn.manifold import TSNE\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "# unused but required import for doing 3d projections with matplotlib < 3.2\n",
        "# import mpl_toolkits.mplot3d  # noqa: F401\n",
        "# from matplotlib import ticker\n",
        "\n",
        "from sklearn import datasets, manifold\n",
        "import json\n",
        "import csv\n",
        "import spacy\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# warnings.filterwarnings(action='ignore',category=UserWarning,module='keyedvectors')\n",
        "# warnings.filterwarnings(action='ignore',category=FutureWarning,module='keyedvectors')"
      ],
      "metadata": {
        "id": "p_qt7cKobRBP"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### movie keyword extraction\n",
        "\n",
        "movieCount = 200  # How many movies from .json\n",
        "keywordCount = 15 # How many keywords for each movie\n",
        "\n",
        "# Data Structures and Models\n",
        "movies = []\n",
        "synopsis = []\n",
        "rows = []\n",
        "kw_model = KeyBERT()\n",
        "sp_model = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Reading .json\n",
        "jsonFilePath = \"movie_data.json\"\n",
        "with open(jsonFilePath, 'r', encoding='utf-8') as jsonFile:\n",
        "    movieReader = (json.loads(line) for line in jsonFile)\n",
        "\n",
        "    count = 0\n",
        "    for movieData in movieReader:\n",
        "        if count >= movieCount:\n",
        "            break\n",
        "        if count % 10 == 0:\n",
        "            print(f'Reading File.. ({count}/{movieCount})')\n",
        "\n",
        "        movieID = movieData.get('movie_id', '')\n",
        "        movies.append(movieID)\n",
        "\n",
        "        movieSummary = movieData.get('plot_synopsis', '')\n",
        "        keywords = kw_model.extract_keywords(movieSummary, top_n=keywordCount)\n",
        "        keyList = [keyword[0] for keyword in keywords]\n",
        "        # extracting needless names\n",
        "        filtered_keywords = []\n",
        "        for keyword in keyList:\n",
        "            doc = sp_model(keyword)\n",
        "            is_name = any(token.ent_type_ == \"PERSON\" and token.ent_iob_ != '0' for token in doc)\n",
        "\n",
        "            if not is_name:\n",
        "                filtered_keywords.append(keyword)\n",
        "\n",
        "        keyString = ', '.join(filtered_keywords)\n",
        "\n",
        "        synopsis.append(keyString)\n",
        "\n",
        "        count += 1"
      ],
      "metadata": {
        "id": "NxtwC4BiARuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing .csv\n",
        "csvFilePath = \"movie_keyword_extraction_\" + str(keywordCount) + \".csv\"\n",
        "with open(csvFilePath, 'w', newline='', encoding='utf-8') as csvFile:\n",
        "    headers = ['MovieID', \"Keywords\"]\n",
        "    writer = csv.DictWriter(csvFile, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for idx in range(0, movieCount):\n",
        "        writer.writerow({'MovieID': movies[idx], 'Keywords': synopsis[idx]})"
      ],
      "metadata": {
        "id": "wqXgLOfLDwNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### book keyword extraction\n",
        "\n",
        "data = []\n",
        "book_ids = []\n",
        "book_summaries = []\n",
        "synopsis = []\n",
        "bookCount = 200\n",
        "keywordCount = 15\n",
        "kw_model = KeyBERT()\n",
        "sp_model = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "with open('booksummaries.txt', 'r') as f:\n",
        "    bookReader = csv.reader(f, dialect='excel-tab')\n",
        "    count = 0\n",
        "    for bookData in bookReader:\n",
        "      if count >= bookCount :\n",
        "        break\n",
        "      if count % 10 == 0:\n",
        "        print(f'Reading File.. ({count}/{bookCount})')\n",
        "\n",
        "      data.append(bookData)\n",
        "      count += 1\n",
        "\n",
        "# convert data to pandas dataframe\n",
        "books = pd.DataFrame.from_records(data, columns=['book_id', 'freebase_id', 'book_title', 'author', 'publication_date', 'genre', 'summary'])"
      ],
      "metadata": {
        "id": "rYQAaL6E-N-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_ids = list(books['book_id'])\n",
        "bookSummary = list(books['summary'])"
      ],
      "metadata": {
        "id": "WsSD_3B3-xDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "for book_idx in range(0, bookCount):\n",
        "    if count >= bookCount:\n",
        "        break\n",
        "    if count % 10 == 0:\n",
        "        print(f'Reading File.. ({count}/{bookCount})')\n",
        "\n",
        "    keywords = kw_model.extract_keywords(bookSummary[book_idx], top_n=keywordCount)\n",
        "    keyList = [keyword[0] for keyword in keywords]\n",
        "    # extracting needless names\n",
        "    filtered_keywords = []\n",
        "    for keyword in keyList:\n",
        "        doc = sp_model(keyword)\n",
        "        is_name = any(token.ent_type_ == \"PERSON\" and token.ent_iob_ != '0' for token in doc)\n",
        "\n",
        "        if not is_name:\n",
        "            filtered_keywords.append(keyword)\n",
        "\n",
        "    keyString = ', '.join(filtered_keywords)\n",
        "\n",
        "    synopsis.append(keyString)\n",
        "\n",
        "    count += 1"
      ],
      "metadata": {
        "id": "tFUoaY2bSSgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing .csv\n",
        "csvFilePath = \"book_keyword_extraction_\" + str(keywordCount) + \".csv\"\n",
        "with open(csvFilePath, 'w', newline='', encoding='utf-8') as csvFile:\n",
        "    headers = ['BookId', \"Keywords\"]\n",
        "    writer = csv.DictWriter(csvFile, fieldnames=headers)\n",
        "    writer.writeheader()\n",
        "\n",
        "    for idx in range(0, bookCount):\n",
        "        writer.writerow({'BookId': book_ids[idx], 'Keywords': synopsis[idx]})"
      ],
      "metadata": {
        "id": "JMxHn_DEwNHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "metadata": {
        "id": "Jv0ndxdJl3z6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "book_data = open(\"book_keyword_extraction_15.csv\", \"r\")\n",
        "movie_data = open(\"movie_keyword_extraction_15.csv\", \"r\")"
      ],
      "metadata": {
        "id": "YB7jCeLsmlMo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_rdr = csv.reader(book_data)\n",
        "movie_rdr = csv.reader(movie_data)"
      ],
      "metadata": {
        "id": "h5WfUuYrna7j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books = {book[0]:book[1].split(',') for book in book_rdr}\n",
        "movies = {movie[0]:movie[1].split(',') for movie in movie_rdr}"
      ],
      "metadata": {
        "id": "yd8mkDHencvD"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_movie(book_id, recommend_count) :\n",
        "  if book_id not in books :\n",
        "    print(\"there is no book\")\n",
        "    return\n",
        "  book_keyword = books[book_id]\n",
        "  if len(book_keyword) == 0 :\n",
        "    print(\"there is no book summarization\")\n",
        "    return\n",
        "  res = []\n",
        "\n",
        "  for movie_id, movie_keyword in movies.items() :\n",
        "    if len(movie_keyword) == 0 :\n",
        "      continue\n",
        "    distance = model.wmdistance(book_keyword, movie_keyword)\n",
        "    res.append({'movie_id' : movie_id, 'distance' : distance})\n",
        "\n",
        "  sorted_res = sorted(res, key=lambda x: x['distance'])\n",
        "\n",
        "  if(len(sorted_res) == 0) :\n",
        "    print(\"there is no movie to recommend\")\n",
        "    return None\n",
        "  if(sorted_res[0]['distance'] == math.inf) :\n",
        "    print(\"there is no movie to recommend\")\n",
        "    return None\n",
        "  return sorted_res[:recommend_count]\n"
      ],
      "metadata": {
        "id": "V4ltNrbVJipW"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = recommend_movie('44472', 2)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "xkzMNbYSF_UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_among_movies(movie_id, recommend_count) :\n",
        "  movie_keyword = movies[movie_id]\n",
        "  res = []\n",
        "\n",
        "  for comp_movie_id, comp_movie_keyword in movies.items() :\n",
        "    if len(comp_movie_keyword) == 0 :\n",
        "      continue\n",
        "    if movie_id == comp_movie_id :\n",
        "      continue\n",
        "    distance = model.wmdistance(movie_keyword, comp_movie_keyword)\n",
        "    res.append({'movie_id' : comp_movie_id, 'distance' : distance})\n",
        "\n",
        "  sorted_res = sorted(res, key=lambda x: x['distance'])\n",
        "  # print(sorted_res)\n",
        "  if(len(sorted_res) == 0) :\n",
        "    print(\"there is no movie to recommend\")\n",
        "    return None\n",
        "  if(sorted_res[0]['distance'] == math.inf) :\n",
        "    print(\"there is no movie to recommend\")\n",
        "    return None\n",
        "\n",
        "  return sorted_res[:recommend_count]"
      ],
      "metadata": {
        "id": "LvnG33D7Q88q"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_among_movies('tt0450259', 5)"
      ],
      "metadata": {
        "id": "iu6ZIcyISCky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_similarity(book_id, movie_id) :\n",
        "  book_keyword = books[book_id]\n",
        "  movie_keyword = movies[movie_id]\n",
        "\n",
        "  all_keywords = book_keyword + movie_keyword\n",
        "\n",
        "  visualize_model = Word2Vec([all_keywords], vector_size=100, window=5, min_count=1, sg=1)\n",
        "\n",
        "  keyword_vectors = np.array([visualize_model.wv[keyword] for keyword in all_keywords])\n",
        "\n",
        "  tsne = TSNE(n_components=2, random_state=42)\n",
        "  embeddings_2d = tsne.fit_transform(keyword_vectors)\n",
        "\n",
        "  # 시각화\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], color='blue')\n",
        "\n",
        "  # 각 데이터 포인트에 해당하는 키워드와 유사도 레이블 추가.\n",
        "  for i, keyword in enumerate(all_keywords):\n",
        "    x, y = embeddings_2d[i]\n",
        "    plt.annotate(f'{keyword} : {visualize_model.wv.similarity(keyword, all_keywords[0]):.2f}', (x, y))\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "_WKe-4aL91mJ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_similarity('1756', 'tt0105112')"
      ],
      "metadata": {
        "id": "6p9pQPUq_Fxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_book_to_movies():\n",
        "  print(\"Book ID: \", end='')\n",
        "  book_id = input()\n",
        "  print(\"Number of movies: \", end='')\n",
        "  movie_count = int(input())\n",
        "\n",
        "  print(\"book id : \" + str(book_id))\n",
        "  print(\"movie_count : \" + str(movie_count))\n",
        "  res = recommend_movie(book_id, movie_count)\n",
        "  print(\"Result\")\n",
        "  print(res)\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def user_movie_to_movies():\n",
        "  print(\"Movie ID: \", end='')\n",
        "  movie_id = input()\n",
        "  print(\"Number of moveis: \", end='')\n",
        "  movie_count = int(input())\n",
        "\n",
        "  res = recommend_among_movies(movie_id, movie_count)\n",
        "  print(\"Result\")\n",
        "  print(res)\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def user_book_movie_similarity():\n",
        "  print(\"Movie ID: \", end='')\n",
        "  movie_id = input()\n",
        "  print(\"Book ID: \", end='')\n",
        "  book_id = input()\n",
        "\n",
        "  show_similarity(book_id, movie_id)\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "def console():\n",
        "    print(\"Enter a command\")\n",
        "    print(\"1: Book To Movies\")\n",
        "    print(\"2: Movie To Movies\")\n",
        "    print(\"3: Book And Movie Similarity\")\n",
        "    print(\"-1 to exit\")\n",
        "\n",
        "    while True:\n",
        "        print(\"Command: \", end='')\n",
        "        command = int(input())\n",
        "\n",
        "        if input == -1:\n",
        "            print(\"Exit Program\")\n",
        "            break\n",
        "\n",
        "        elif input == 1:\n",
        "            user_book_to_movies()\n",
        "        elif input == 2:\n",
        "            user_movie_to_movies()\n",
        "        elif input == 3:\n",
        "            user_book_movie_similarity()\n",
        "        else:\n",
        "            print(\"Invalid Command\")\n",
        "\n",
        "\n",
        "def console():\n",
        "    print(\"Enter a command\")\n",
        "    print(\"1: Book To Movies\")\n",
        "    print(\"2: Movie To Movies\")\n",
        "    print(\"3: Book And Movie Similarity\")\n",
        "    print(\"-1 to exit\")\n",
        "\n",
        "    while True:\n",
        "        print(\"Command: \", end='')\n",
        "        command = int(input())\n",
        "\n",
        "        if command == -1:\n",
        "            print(\"Exit Program\")\n",
        "            break\n",
        "\n",
        "        elif command == 1:\n",
        "            user_book_to_movies()\n",
        "        elif command == 2:\n",
        "            user_movie_to_movies()\n",
        "        elif command == 3:\n",
        "            user_book_movie_similarity()\n",
        "        else:\n",
        "            print(\"Invalid Command\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "PrW3EMJpaHko"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "console()"
      ],
      "metadata": {
        "id": "pbkCOsnkaN65"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}